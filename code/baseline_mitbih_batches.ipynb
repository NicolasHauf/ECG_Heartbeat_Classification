{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6b1a0e82-999e-459b-92ae-99659e380fdb",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-10-17 10:48:56.596358: I external/local_xla/xla/tsl/cuda/cudart_stub.cc:32] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2024-10-17 10:48:56.663887: I external/local_xla/xla/tsl/cuda/cudart_stub.cc:32] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2024-10-17 10:48:56.796642: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:485] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2024-10-17 10:48:56.957153: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:8454] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2024-10-17 10:48:57.003603: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1452] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2024-10-17 10:48:57.231069: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-10-17 10:48:59.610684: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from keras import optimizers, losses, activations, models\n",
    "from keras.callbacks import ModelCheckpoint, EarlyStopping, LearningRateScheduler, ReduceLROnPlateau\n",
    "from keras.layers import Dense, Input, Dropout, Convolution1D, MaxPool1D, GlobalMaxPool1D, GlobalAveragePooling1D, \\\n",
    "    concatenate\n",
    "from sklearn.metrics import f1_score, accuracy_score\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e61f5111-f819-4ce7-a13a-b2c3b798fe41",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-10-16 15:14:28.886460: I external/local_xla/xla/tsl/cuda/cudart_stub.cc:32] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2024-10-16 15:14:28.962504: I external/local_xla/xla/tsl/cuda/cudart_stub.cc:32] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2024-10-16 15:14:29.042385: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:485] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2024-10-16 15:14:29.111673: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:8454] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2024-10-16 15:14:29.132945: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1452] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2024-10-16 15:14:29.269735: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-10-16 15:14:30.612193: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1000\n",
      "\n",
      "Epoch 1: val_acc improved from -inf to 0.88225, saving model to baseline_cnn_mitbih.keras\n",
      "308/308 - 28s - 92ms/step - acc: 0.8505 - loss: 0.5129 - val_acc: 0.8823 - val_loss: 0.3715 - learning_rate: 0.0010\n",
      "Epoch 2/1000\n",
      "\n",
      "Epoch 2: val_acc improved from 0.88225 to 0.93227, saving model to baseline_cnn_mitbih.keras\n",
      "308/308 - 24s - 79ms/step - acc: 0.9043 - loss: 0.3320 - val_acc: 0.9323 - val_loss: 0.2329 - learning_rate: 0.0010\n",
      "Epoch 3/1000\n",
      "\n",
      "Epoch 3: val_acc improved from 0.93227 to 0.94050, saving model to baseline_cnn_mitbih.keras\n",
      "308/308 - 24s - 79ms/step - acc: 0.9332 - loss: 0.2436 - val_acc: 0.9405 - val_loss: 0.1999 - learning_rate: 0.0010\n",
      "Epoch 4/1000\n",
      "\n",
      "Epoch 4: val_acc improved from 0.94050 to 0.95306, saving model to baseline_cnn_mitbih.keras\n",
      "308/308 - 24s - 78ms/step - acc: 0.9415 - loss: 0.2092 - val_acc: 0.9531 - val_loss: 0.1717 - learning_rate: 0.0010\n",
      "Epoch 5/1000\n",
      "\n",
      "Epoch 5: val_acc improved from 0.95306 to 0.95763, saving model to baseline_cnn_mitbih.keras\n",
      "308/308 - 24s - 78ms/step - acc: 0.9480 - loss: 0.1849 - val_acc: 0.9576 - val_loss: 0.1530 - learning_rate: 0.0010\n",
      "Epoch 6/1000\n",
      "\n",
      "Epoch 6: val_acc improved from 0.95763 to 0.96699, saving model to baseline_cnn_mitbih.keras\n",
      "308/308 - 24s - 78ms/step - acc: 0.9540 - loss: 0.1625 - val_acc: 0.9670 - val_loss: 0.1204 - learning_rate: 0.0010\n",
      "Epoch 7/1000\n",
      "\n",
      "Epoch 7: val_acc improved from 0.96699 to 0.97008, saving model to baseline_cnn_mitbih.keras\n",
      "308/308 - 24s - 78ms/step - acc: 0.9606 - loss: 0.1411 - val_acc: 0.9701 - val_loss: 0.1117 - learning_rate: 0.0010\n",
      "Epoch 8/1000\n",
      "\n",
      "Epoch 8: val_acc improved from 0.97008 to 0.97385, saving model to baseline_cnn_mitbih.keras\n",
      "308/308 - 27s - 87ms/step - acc: 0.9656 - loss: 0.1255 - val_acc: 0.9738 - val_loss: 0.0954 - learning_rate: 0.0010\n",
      "Epoch 9/1000\n",
      "\n",
      "Epoch 9: val_acc improved from 0.97385 to 0.97590, saving model to baseline_cnn_mitbih.keras\n",
      "308/308 - 24s - 78ms/step - acc: 0.9685 - loss: 0.1146 - val_acc: 0.9759 - val_loss: 0.0897 - learning_rate: 0.0010\n",
      "Epoch 10/1000\n",
      "\n",
      "Epoch 10: val_acc did not improve from 0.97590\n",
      "308/308 - 24s - 77ms/step - acc: 0.9700 - loss: 0.1080 - val_acc: 0.9729 - val_loss: 0.0972 - learning_rate: 0.0010\n",
      "Epoch 11/1000\n",
      "\n",
      "Epoch 11: val_acc improved from 0.97590 to 0.97796, saving model to baseline_cnn_mitbih.keras\n",
      "308/308 - 24s - 78ms/step - acc: 0.9719 - loss: 0.1021 - val_acc: 0.9780 - val_loss: 0.0779 - learning_rate: 0.0010\n",
      "Epoch 12/1000\n",
      "\n",
      "Epoch 12: val_acc did not improve from 0.97796\n",
      "308/308 - 24s - 78ms/step - acc: 0.9740 - loss: 0.0939 - val_acc: 0.9775 - val_loss: 0.0795 - learning_rate: 0.0010\n",
      "Epoch 13/1000\n",
      "\n",
      "Epoch 13: val_acc improved from 0.97796 to 0.97921, saving model to baseline_cnn_mitbih.keras\n",
      "308/308 - 24s - 78ms/step - acc: 0.9746 - loss: 0.0888 - val_acc: 0.9792 - val_loss: 0.0727 - learning_rate: 0.0010\n",
      "Epoch 14/1000\n",
      "\n",
      "Epoch 14: val_acc improved from 0.97921 to 0.98047, saving model to baseline_cnn_mitbih.keras\n",
      "308/308 - 24s - 79ms/step - acc: 0.9745 - loss: 0.0875 - val_acc: 0.9805 - val_loss: 0.0667 - learning_rate: 0.0010\n",
      "Epoch 15/1000\n",
      "\n",
      "Epoch 15: val_acc improved from 0.98047 to 0.98138, saving model to baseline_cnn_mitbih.keras\n",
      "308/308 - 24s - 78ms/step - acc: 0.9763 - loss: 0.0827 - val_acc: 0.9814 - val_loss: 0.0678 - learning_rate: 0.0010\n",
      "Epoch 16/1000\n",
      "\n",
      "Epoch 16: val_acc did not improve from 0.98138\n",
      "308/308 - 24s - 78ms/step - acc: 0.9764 - loss: 0.0799 - val_acc: 0.9814 - val_loss: 0.0642 - learning_rate: 0.0010\n",
      "Epoch 17/1000\n",
      "\n",
      "Epoch 17: val_acc improved from 0.98138 to 0.98333, saving model to baseline_cnn_mitbih.keras\n",
      "308/308 - 24s - 78ms/step - acc: 0.9770 - loss: 0.0784 - val_acc: 0.9833 - val_loss: 0.0586 - learning_rate: 0.0010\n",
      "Epoch 18/1000\n",
      "\n",
      "Epoch 18: val_acc did not improve from 0.98333\n",
      "308/308 - 24s - 79ms/step - acc: 0.9788 - loss: 0.0730 - val_acc: 0.9818 - val_loss: 0.0597 - learning_rate: 0.0010\n",
      "Epoch 19/1000\n",
      "\n",
      "Epoch 19: val_acc did not improve from 0.98333\n",
      "308/308 - 24s - 78ms/step - acc: 0.9797 - loss: 0.0692 - val_acc: 0.9829 - val_loss: 0.0598 - learning_rate: 0.0010\n",
      "Epoch 20/1000\n",
      "\n",
      "Epoch 20: val_acc improved from 0.98333 to 0.98481, saving model to baseline_cnn_mitbih.keras\n",
      "308/308 - 24s - 78ms/step - acc: 0.9802 - loss: 0.0674 - val_acc: 0.9848 - val_loss: 0.0524 - learning_rate: 0.0010\n",
      "Epoch 21/1000\n",
      "\n",
      "Epoch 21: val_acc did not improve from 0.98481\n",
      "308/308 - 25s - 81ms/step - acc: 0.9808 - loss: 0.0649 - val_acc: 0.9840 - val_loss: 0.0545 - learning_rate: 0.0010\n",
      "Epoch 22/1000\n",
      "\n",
      "Epoch 22: val_acc did not improve from 0.98481\n",
      "308/308 - 24s - 77ms/step - acc: 0.9801 - loss: 0.0664 - val_acc: 0.9841 - val_loss: 0.0543 - learning_rate: 0.0010\n",
      "Epoch 23/1000\n",
      "\n",
      "Epoch 23: val_acc improved from 0.98481 to 0.98527, saving model to baseline_cnn_mitbih.keras\n",
      "308/308 - 24s - 78ms/step - acc: 0.9816 - loss: 0.0620 - val_acc: 0.9853 - val_loss: 0.0507 - learning_rate: 0.0010\n",
      "Epoch 24/1000\n",
      "\n",
      "Epoch 24: val_acc improved from 0.98527 to 0.98538, saving model to baseline_cnn_mitbih.keras\n",
      "308/308 - 24s - 78ms/step - acc: 0.9826 - loss: 0.0587 - val_acc: 0.9854 - val_loss: 0.0525 - learning_rate: 0.0010\n",
      "Epoch 25/1000\n",
      "\n",
      "Epoch 25: val_acc did not improve from 0.98538\n",
      "308/308 - 24s - 79ms/step - acc: 0.9826 - loss: 0.0586 - val_acc: 0.9845 - val_loss: 0.0540 - learning_rate: 0.0010\n",
      "Epoch 26/1000\n",
      "\n",
      "Epoch 26: val_acc did not improve from 0.98538\n",
      "308/308 - 24s - 78ms/step - acc: 0.9827 - loss: 0.0573 - val_acc: 0.9842 - val_loss: 0.0536 - learning_rate: 0.0010\n",
      "Epoch 27/1000\n",
      "\n",
      "Epoch 27: val_acc improved from 0.98538 to 0.98687, saving model to baseline_cnn_mitbih.keras\n",
      "308/308 - 24s - 78ms/step - acc: 0.9835 - loss: 0.0558 - val_acc: 0.9869 - val_loss: 0.0476 - learning_rate: 0.0010\n",
      "Epoch 28/1000\n",
      "\n",
      "Epoch 28: val_acc did not improve from 0.98687\n",
      "308/308 - 24s - 79ms/step - acc: 0.9837 - loss: 0.0540 - val_acc: 0.9869 - val_loss: 0.0460 - learning_rate: 0.0010\n",
      "Epoch 29/1000\n",
      "\n",
      "Epoch 29: val_acc did not improve from 0.98687\n",
      "308/308 - 24s - 78ms/step - acc: 0.9839 - loss: 0.0535 - val_acc: 0.9840 - val_loss: 0.0542 - learning_rate: 0.0010\n",
      "Epoch 30/1000\n",
      "\n",
      "Epoch 30: val_acc did not improve from 0.98687\n",
      "\n",
      "Epoch 30: ReduceLROnPlateau reducing learning rate to 0.00010000000474974513.\n",
      "308/308 - 24s - 77ms/step - acc: 0.9838 - loss: 0.0521 - val_acc: 0.9855 - val_loss: 0.0487 - learning_rate: 0.0010\n",
      "Epoch 31/1000\n",
      "\n",
      "Epoch 31: val_acc improved from 0.98687 to 0.98812, saving model to baseline_cnn_mitbih.keras\n",
      "308/308 - 24s - 78ms/step - acc: 0.9867 - loss: 0.0428 - val_acc: 0.9881 - val_loss: 0.0404 - learning_rate: 1.0000e-04\n",
      "Epoch 32/1000\n",
      "\n",
      "Epoch 32: val_acc improved from 0.98812 to 0.98904, saving model to baseline_cnn_mitbih.keras\n",
      "308/308 - 24s - 78ms/step - acc: 0.9879 - loss: 0.0390 - val_acc: 0.9890 - val_loss: 0.0392 - learning_rate: 1.0000e-04\n",
      "Epoch 33/1000\n",
      "\n",
      "Epoch 33: val_acc improved from 0.98904 to 0.98915, saving model to baseline_cnn_mitbih.keras\n",
      "308/308 - 25s - 80ms/step - acc: 0.9880 - loss: 0.0380 - val_acc: 0.9892 - val_loss: 0.0395 - learning_rate: 1.0000e-04\n",
      "Epoch 34/1000\n",
      "\n",
      "Epoch 34: val_acc did not improve from 0.98915\n",
      "308/308 - 31s - 101ms/step - acc: 0.9883 - loss: 0.0366 - val_acc: 0.9892 - val_loss: 0.0386 - learning_rate: 1.0000e-04\n",
      "Epoch 35/1000\n",
      "\n",
      "Epoch 35: val_acc improved from 0.98915 to 0.98972, saving model to baseline_cnn_mitbih.keras\n",
      "308/308 - 29s - 93ms/step - acc: 0.9888 - loss: 0.0371 - val_acc: 0.9897 - val_loss: 0.0385 - learning_rate: 1.0000e-04\n",
      "Epoch 36/1000\n",
      "\n",
      "Epoch 36: val_acc did not improve from 0.98972\n",
      "308/308 - 30s - 99ms/step - acc: 0.9880 - loss: 0.0370 - val_acc: 0.9888 - val_loss: 0.0379 - learning_rate: 1.0000e-04\n",
      "Epoch 37/1000\n",
      "\n",
      "Epoch 37: val_acc did not improve from 0.98972\n",
      "308/308 - 26s - 84ms/step - acc: 0.9883 - loss: 0.0357 - val_acc: 0.9890 - val_loss: 0.0382 - learning_rate: 1.0000e-04\n",
      "Epoch 38/1000\n",
      "\n",
      "Epoch 38: val_acc did not improve from 0.98972\n",
      "\n",
      "Epoch 38: ReduceLROnPlateau reducing learning rate to 1.0000000474974514e-05.\n",
      "308/308 - 28s - 90ms/step - acc: 0.9887 - loss: 0.0356 - val_acc: 0.9889 - val_loss: 0.0381 - learning_rate: 1.0000e-04\n",
      "Epoch 39/1000\n",
      "\n",
      "Epoch 39: val_acc did not improve from 0.98972\n",
      "308/308 - 26s - 85ms/step - acc: 0.9892 - loss: 0.0339 - val_acc: 0.9890 - val_loss: 0.0379 - learning_rate: 1.0000e-05\n",
      "Epoch 40/1000\n",
      "\n",
      "Epoch 40: val_acc did not improve from 0.98972\n",
      "308/308 - 27s - 86ms/step - acc: 0.9892 - loss: 0.0343 - val_acc: 0.9892 - val_loss: 0.0378 - learning_rate: 1.0000e-05\n",
      "Epoch 40: early stopping\n",
      "\u001b[1m685/685\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 7ms/step\n",
      "\n",
      "\n",
      "\n",
      "Batch size:  256\n",
      "Test f1 score : 0.9176456348044404 \n",
      "Test accuracy score : 0.9853371094463731 \n",
      "Total time elapsed: 1004.9752607345581\n",
      "Epoch 1/1000\n",
      "\n",
      "Epoch 1: val_acc improved from -inf to 0.93867, saving model to baseline_cnn_mitbih.keras\n",
      "2463/2463 - 37s - 15ms/step - acc: 0.8912 - loss: 0.3715 - val_acc: 0.9387 - val_loss: 0.2185 - learning_rate: 0.0010\n",
      "Epoch 2/1000\n",
      "\n",
      "Epoch 2: val_acc improved from 0.93867 to 0.95946, saving model to baseline_cnn_mitbih.keras\n",
      "2463/2463 - 35s - 14ms/step - acc: 0.9419 - loss: 0.2061 - val_acc: 0.9595 - val_loss: 0.1479 - learning_rate: 0.0010\n",
      "Epoch 3/1000\n",
      "\n",
      "Epoch 3: val_acc improved from 0.95946 to 0.96779, saving model to baseline_cnn_mitbih.keras\n",
      "2463/2463 - 36s - 15ms/step - acc: 0.9571 - loss: 0.1570 - val_acc: 0.9678 - val_loss: 0.1201 - learning_rate: 0.0010\n",
      "Epoch 4/1000\n",
      "\n",
      "Epoch 4: val_acc improved from 0.96779 to 0.97099, saving model to baseline_cnn_mitbih.keras\n",
      "2463/2463 - 35s - 14ms/step - acc: 0.9634 - loss: 0.1348 - val_acc: 0.9710 - val_loss: 0.1058 - learning_rate: 0.0010\n",
      "Epoch 5/1000\n",
      "\n",
      "Epoch 5: val_acc improved from 0.97099 to 0.97579, saving model to baseline_cnn_mitbih.keras\n",
      "2463/2463 - 34s - 14ms/step - acc: 0.9677 - loss: 0.1196 - val_acc: 0.9758 - val_loss: 0.0892 - learning_rate: 0.0010\n",
      "Epoch 6/1000\n",
      "\n",
      "Epoch 6: val_acc did not improve from 0.97579\n",
      "2463/2463 - 34s - 14ms/step - acc: 0.9690 - loss: 0.1116 - val_acc: 0.9748 - val_loss: 0.0856 - learning_rate: 0.0010\n",
      "Epoch 7/1000\n",
      "\n",
      "Epoch 7: val_acc did not improve from 0.97579\n",
      "2463/2463 - 37s - 15ms/step - acc: 0.9716 - loss: 0.1028 - val_acc: 0.9702 - val_loss: 0.1146 - learning_rate: 0.0010\n",
      "Epoch 8/1000\n",
      "\n",
      "Epoch 8: val_acc improved from 0.97579 to 0.97773, saving model to baseline_cnn_mitbih.keras\n",
      "2463/2463 - 34s - 14ms/step - acc: 0.9729 - loss: 0.0974 - val_acc: 0.9777 - val_loss: 0.0788 - learning_rate: 0.0010\n",
      "Epoch 9/1000\n",
      "\n",
      "Epoch 9: val_acc improved from 0.97773 to 0.98093, saving model to baseline_cnn_mitbih.keras\n",
      "2463/2463 - 36s - 15ms/step - acc: 0.9743 - loss: 0.0911 - val_acc: 0.9809 - val_loss: 0.0680 - learning_rate: 0.0010\n",
      "Epoch 10/1000\n",
      "\n",
      "Epoch 10: val_acc improved from 0.98093 to 0.98161, saving model to baseline_cnn_mitbih.keras\n",
      "2463/2463 - 36s - 15ms/step - acc: 0.9751 - loss: 0.0859 - val_acc: 0.9816 - val_loss: 0.0619 - learning_rate: 0.0010\n",
      "Epoch 11/1000\n",
      "\n",
      "Epoch 11: val_acc improved from 0.98161 to 0.98275, saving model to baseline_cnn_mitbih.keras\n",
      "2463/2463 - 40s - 16ms/step - acc: 0.9758 - loss: 0.0826 - val_acc: 0.9828 - val_loss: 0.0581 - learning_rate: 0.0010\n",
      "Epoch 12/1000\n",
      "\n",
      "Epoch 12: val_acc improved from 0.98275 to 0.98344, saving model to baseline_cnn_mitbih.keras\n",
      "2463/2463 - 50s - 20ms/step - acc: 0.9769 - loss: 0.0798 - val_acc: 0.9834 - val_loss: 0.0588 - learning_rate: 0.0010\n",
      "Epoch 13/1000\n",
      "\n",
      "Epoch 13: val_acc improved from 0.98344 to 0.98401, saving model to baseline_cnn_mitbih.keras\n",
      "2463/2463 - 40s - 16ms/step - acc: 0.9777 - loss: 0.0775 - val_acc: 0.9840 - val_loss: 0.0534 - learning_rate: 0.0010\n",
      "Epoch 14/1000\n",
      "\n",
      "Epoch 14: val_acc did not improve from 0.98401\n",
      "2463/2463 - 36s - 15ms/step - acc: 0.9784 - loss: 0.0750 - val_acc: 0.9839 - val_loss: 0.0542 - learning_rate: 0.0010\n",
      "Epoch 15/1000\n",
      "\n",
      "Epoch 15: val_acc did not improve from 0.98401\n",
      "2463/2463 - 35s - 14ms/step - acc: 0.9795 - loss: 0.0702 - val_acc: 0.9833 - val_loss: 0.0596 - learning_rate: 0.0010\n",
      "Epoch 16/1000\n",
      "\n",
      "Epoch 16: val_acc did not improve from 0.98401\n",
      "\n",
      "Epoch 16: ReduceLROnPlateau reducing learning rate to 0.00010000000474974513.\n",
      "2463/2463 - 40s - 16ms/step - acc: 0.9795 - loss: 0.0710 - val_acc: 0.9840 - val_loss: 0.0526 - learning_rate: 0.0010\n",
      "Epoch 17/1000\n",
      "\n",
      "Epoch 17: val_acc improved from 0.98401 to 0.98618, saving model to baseline_cnn_mitbih.keras\n",
      "2463/2463 - 37s - 15ms/step - acc: 0.9841 - loss: 0.0527 - val_acc: 0.9862 - val_loss: 0.0449 - learning_rate: 1.0000e-04\n",
      "Epoch 18/1000\n",
      "\n",
      "Epoch 18: val_acc improved from 0.98618 to 0.98709, saving model to baseline_cnn_mitbih.keras\n",
      "2463/2463 - 36s - 15ms/step - acc: 0.9857 - loss: 0.0467 - val_acc: 0.9871 - val_loss: 0.0432 - learning_rate: 1.0000e-04\n",
      "Epoch 19/1000\n",
      "\n",
      "Epoch 19: val_acc improved from 0.98709 to 0.98755, saving model to baseline_cnn_mitbih.keras\n",
      "2463/2463 - 37s - 15ms/step - acc: 0.9862 - loss: 0.0450 - val_acc: 0.9876 - val_loss: 0.0427 - learning_rate: 1.0000e-04\n",
      "Epoch 20/1000\n",
      "\n",
      "Epoch 20: val_acc did not improve from 0.98755\n",
      "2463/2463 - 34s - 14ms/step - acc: 0.9867 - loss: 0.0427 - val_acc: 0.9874 - val_loss: 0.0431 - learning_rate: 1.0000e-04\n",
      "Epoch 21/1000\n",
      "\n",
      "Epoch 21: val_acc did not improve from 0.98755\n",
      "2463/2463 - 34s - 14ms/step - acc: 0.9872 - loss: 0.0422 - val_acc: 0.9869 - val_loss: 0.0420 - learning_rate: 1.0000e-04\n",
      "Epoch 22/1000\n",
      "\n",
      "Epoch 22: val_acc improved from 0.98755 to 0.98801, saving model to baseline_cnn_mitbih.keras\n",
      "2463/2463 - 35s - 14ms/step - acc: 0.9872 - loss: 0.0408 - val_acc: 0.9880 - val_loss: 0.0408 - learning_rate: 1.0000e-04\n",
      "Epoch 23/1000\n",
      "\n",
      "Epoch 23: val_acc did not improve from 0.98801\n",
      "2463/2463 - 35s - 14ms/step - acc: 0.9872 - loss: 0.0404 - val_acc: 0.9877 - val_loss: 0.0400 - learning_rate: 1.0000e-04\n",
      "Epoch 24/1000\n",
      "\n",
      "Epoch 24: val_acc improved from 0.98801 to 0.98824, saving model to baseline_cnn_mitbih.keras\n",
      "2463/2463 - 35s - 14ms/step - acc: 0.9873 - loss: 0.0396 - val_acc: 0.9882 - val_loss: 0.0400 - learning_rate: 1.0000e-04\n",
      "Epoch 25/1000\n",
      "\n",
      "Epoch 25: val_acc did not improve from 0.98824\n",
      "2463/2463 - 34s - 14ms/step - acc: 0.9873 - loss: 0.0396 - val_acc: 0.9881 - val_loss: 0.0402 - learning_rate: 1.0000e-04\n",
      "Epoch 26/1000\n",
      "\n",
      "Epoch 26: val_acc improved from 0.98824 to 0.98847, saving model to baseline_cnn_mitbih.keras\n",
      "2463/2463 - 34s - 14ms/step - acc: 0.9880 - loss: 0.0387 - val_acc: 0.9885 - val_loss: 0.0400 - learning_rate: 1.0000e-04\n",
      "Epoch 27/1000\n",
      "\n",
      "Epoch 27: val_acc did not improve from 0.98847\n",
      "2463/2463 - 35s - 14ms/step - acc: 0.9882 - loss: 0.0375 - val_acc: 0.9884 - val_loss: 0.0396 - learning_rate: 1.0000e-04\n",
      "Epoch 28/1000\n",
      "\n",
      "Epoch 28: val_acc improved from 0.98847 to 0.98938, saving model to baseline_cnn_mitbih.keras\n",
      "2463/2463 - 36s - 14ms/step - acc: 0.9881 - loss: 0.0373 - val_acc: 0.9894 - val_loss: 0.0397 - learning_rate: 1.0000e-04\n",
      "Epoch 29/1000\n",
      "\n",
      "Epoch 29: val_acc did not improve from 0.98938\n",
      "2463/2463 - 36s - 14ms/step - acc: 0.9883 - loss: 0.0369 - val_acc: 0.9893 - val_loss: 0.0395 - learning_rate: 1.0000e-04\n",
      "Epoch 30/1000\n",
      "\n",
      "Epoch 30: val_acc did not improve from 0.98938\n",
      "2463/2463 - 34s - 14ms/step - acc: 0.9887 - loss: 0.0363 - val_acc: 0.9892 - val_loss: 0.0384 - learning_rate: 1.0000e-04\n",
      "Epoch 31/1000\n",
      "\n",
      "Epoch 31: val_acc did not improve from 0.98938\n",
      "\n",
      "Epoch 31: ReduceLROnPlateau reducing learning rate to 1.0000000474974514e-05.\n",
      "2463/2463 - 35s - 14ms/step - acc: 0.9885 - loss: 0.0362 - val_acc: 0.9893 - val_loss: 0.0389 - learning_rate: 1.0000e-04\n",
      "Epoch 32/1000\n",
      "\n",
      "Epoch 32: val_acc did not improve from 0.98938\n",
      "2463/2463 - 35s - 14ms/step - acc: 0.9891 - loss: 0.0330 - val_acc: 0.9894 - val_loss: 0.0387 - learning_rate: 1.0000e-05\n",
      "Epoch 33/1000\n",
      "\n",
      "Epoch 33: val_acc improved from 0.98938 to 0.98949, saving model to baseline_cnn_mitbih.keras\n",
      "2463/2463 - 36s - 15ms/step - acc: 0.9891 - loss: 0.0341 - val_acc: 0.9895 - val_loss: 0.0385 - learning_rate: 1.0000e-05\n",
      "Epoch 34/1000\n",
      "\n",
      "Epoch 34: val_acc did not improve from 0.98949\n",
      "2463/2463 - 35s - 14ms/step - acc: 0.9889 - loss: 0.0337 - val_acc: 0.9893 - val_loss: 0.0384 - learning_rate: 1.0000e-05\n",
      "Epoch 35/1000\n",
      "\n",
      "Epoch 35: val_acc did not improve from 0.98949\n",
      "2463/2463 - 34s - 14ms/step - acc: 0.9896 - loss: 0.0323 - val_acc: 0.9895 - val_loss: 0.0389 - learning_rate: 1.0000e-05\n",
      "Epoch 36/1000\n",
      "\n",
      "Epoch 36: val_acc improved from 0.98949 to 0.98995, saving model to baseline_cnn_mitbih.keras\n",
      "2463/2463 - 36s - 15ms/step - acc: 0.9893 - loss: 0.0325 - val_acc: 0.9899 - val_loss: 0.0387 - learning_rate: 1.0000e-05\n",
      "Epoch 37/1000\n",
      "\n",
      "Epoch 37: val_acc did not improve from 0.98995\n",
      "2463/2463 - 34s - 14ms/step - acc: 0.9895 - loss: 0.0324 - val_acc: 0.9896 - val_loss: 0.0385 - learning_rate: 1.0000e-05\n",
      "Epoch 38/1000\n",
      "\n",
      "Epoch 38: val_acc did not improve from 0.98995\n",
      "2463/2463 - 34s - 14ms/step - acc: 0.9897 - loss: 0.0322 - val_acc: 0.9895 - val_loss: 0.0388 - learning_rate: 1.0000e-05\n",
      "Epoch 39/1000\n",
      "\n",
      "Epoch 39: val_acc did not improve from 0.98995\n",
      "\n",
      "Epoch 39: ReduceLROnPlateau reducing learning rate to 1.0000000656873453e-06.\n",
      "2463/2463 - 35s - 14ms/step - acc: 0.9893 - loss: 0.0329 - val_acc: 0.9897 - val_loss: 0.0390 - learning_rate: 1.0000e-05\n",
      "Epoch 40/1000\n",
      "\n",
      "Epoch 40: val_acc did not improve from 0.98995\n",
      "2463/2463 - 34s - 14ms/step - acc: 0.9895 - loss: 0.0319 - val_acc: 0.9896 - val_loss: 0.0390 - learning_rate: 1.0000e-06\n",
      "Epoch 41/1000\n",
      "\n",
      "Epoch 41: val_acc did not improve from 0.98995\n",
      "2463/2463 - 34s - 14ms/step - acc: 0.9897 - loss: 0.0317 - val_acc: 0.9896 - val_loss: 0.0390 - learning_rate: 1.0000e-06\n",
      "Epoch 41: early stopping\n",
      "\u001b[1m685/685\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step\n",
      "\n",
      "\n",
      "\n",
      "Batch size:  32\n",
      "Test f1 score : 0.9149169710612826 \n",
      "Test accuracy score : 0.9852914306596017 \n",
      "Total time elapsed: 1476.2392041683197\n",
      "Epoch 1/1000\n",
      "\n",
      "Epoch 1: val_acc improved from -inf to 0.94107, saving model to baseline_cnn_mitbih.keras\n",
      "9850/9850 - 643s - 65ms/step - acc: 0.9041 - loss: 0.3318 - val_acc: 0.9411 - val_loss: 0.1991 - learning_rate: 0.0010\n",
      "Epoch 2/1000\n",
      "\n",
      "Epoch 2: val_acc improved from 0.94107 to 0.96140, saving model to baseline_cnn_mitbih.keras\n",
      "9850/9850 - 136s - 14ms/step - acc: 0.9443 - loss: 0.1985 - val_acc: 0.9614 - val_loss: 0.1405 - learning_rate: 0.0010\n",
      "Epoch 3/1000\n",
      "\n",
      "Epoch 3: val_acc improved from 0.96140 to 0.96254, saving model to baseline_cnn_mitbih.keras\n",
      "9850/9850 - 148s - 15ms/step - acc: 0.9542 - loss: 0.1652 - val_acc: 0.9625 - val_loss: 0.1378 - learning_rate: 0.0010\n",
      "Epoch 4/1000\n",
      "\n",
      "Epoch 4: val_acc improved from 0.96254 to 0.97008, saving model to baseline_cnn_mitbih.keras\n",
      "9850/9850 - 165s - 17ms/step - acc: 0.9587 - loss: 0.1510 - val_acc: 0.9701 - val_loss: 0.1210 - learning_rate: 0.0010\n",
      "Epoch 5/1000\n",
      "\n",
      "Epoch 5: val_acc did not improve from 0.97008\n",
      "9850/9850 - 165s - 17ms/step - acc: 0.9623 - loss: 0.1403 - val_acc: 0.9627 - val_loss: 0.1335 - learning_rate: 0.0010\n",
      "Epoch 6/1000\n",
      "\n",
      "Epoch 6: val_acc improved from 0.97008 to 0.97111, saving model to baseline_cnn_mitbih.keras\n",
      "9850/9850 - 163s - 17ms/step - acc: 0.9634 - loss: 0.1349 - val_acc: 0.9711 - val_loss: 0.1038 - learning_rate: 0.0010\n",
      "Epoch 7/1000\n",
      "\n",
      "Epoch 7: val_acc improved from 0.97111 to 0.97156, saving model to baseline_cnn_mitbih.keras\n",
      "9850/9850 - 165s - 17ms/step - acc: 0.9653 - loss: 0.1272 - val_acc: 0.9716 - val_loss: 0.1055 - learning_rate: 0.0010\n",
      "Epoch 8/1000\n",
      "\n",
      "Epoch 8: val_acc improved from 0.97156 to 0.97487, saving model to baseline_cnn_mitbih.keras\n",
      "9850/9850 - 144s - 15ms/step - acc: 0.9659 - loss: 0.1227 - val_acc: 0.9749 - val_loss: 0.0926 - learning_rate: 0.0010\n",
      "Epoch 9/1000\n",
      "\n",
      "Epoch 9: val_acc did not improve from 0.97487\n",
      "9850/9850 - 145s - 15ms/step - acc: 0.9668 - loss: 0.1274 - val_acc: 0.9726 - val_loss: 0.1070 - learning_rate: 0.0010\n",
      "Epoch 10/1000\n",
      "\n",
      "Epoch 10: val_acc did not improve from 0.97487\n",
      "9850/9850 - 150s - 15ms/step - acc: 0.9679 - loss: 0.1186 - val_acc: 0.9746 - val_loss: 0.0976 - learning_rate: 0.0010\n",
      "Epoch 11/1000\n",
      "\n",
      "Epoch 11: val_acc improved from 0.97487 to 0.97613, saving model to baseline_cnn_mitbih.keras\n",
      "9850/9850 - 153s - 16ms/step - acc: 0.9680 - loss: 0.1199 - val_acc: 0.9761 - val_loss: 0.0931 - learning_rate: 0.0010\n",
      "Epoch 12/1000\n",
      "\n",
      "Epoch 12: val_acc did not improve from 0.97613\n",
      "9850/9850 - 162s - 16ms/step - acc: 0.9687 - loss: 0.1169 - val_acc: 0.9750 - val_loss: 0.0914 - learning_rate: 0.0010\n",
      "Epoch 13/1000\n",
      "\n",
      "Epoch 13: val_acc did not improve from 0.97613\n",
      "9850/9850 - 156s - 16ms/step - acc: 0.9696 - loss: 0.1113 - val_acc: 0.9750 - val_loss: 0.0906 - learning_rate: 0.0010\n",
      "Epoch 14/1000\n",
      "\n",
      "Epoch 14: val_acc did not improve from 0.97613\n",
      "\n",
      "Epoch 14: ReduceLROnPlateau reducing learning rate to 0.00010000000474974513.\n",
      "9850/9850 - 173s - 18ms/step - acc: 0.9688 - loss: 0.1193 - val_acc: 0.9759 - val_loss: 0.0934 - learning_rate: 0.0010\n",
      "Epoch 15/1000\n",
      "\n",
      "Epoch 15: val_acc improved from 0.97613 to 0.97944, saving model to baseline_cnn_mitbih.keras\n",
      "9850/9850 - 164s - 17ms/step - acc: 0.9768 - loss: 0.0831 - val_acc: 0.9794 - val_loss: 0.0735 - learning_rate: 1.0000e-04\n",
      "Epoch 16/1000\n",
      "\n",
      "Epoch 16: val_acc improved from 0.97944 to 0.97956, saving model to baseline_cnn_mitbih.keras\n",
      "9850/9850 - 160s - 16ms/step - acc: 0.9784 - loss: 0.0748 - val_acc: 0.9796 - val_loss: 0.0698 - learning_rate: 1.0000e-04\n",
      "Epoch 17/1000\n",
      "\n",
      "Epoch 17: val_acc improved from 0.97956 to 0.97967, saving model to baseline_cnn_mitbih.keras\n",
      "9850/9850 - 159s - 16ms/step - acc: 0.9801 - loss: 0.0711 - val_acc: 0.9797 - val_loss: 0.0716 - learning_rate: 1.0000e-04\n",
      "Epoch 18/1000\n",
      "\n",
      "Epoch 18: val_acc improved from 0.97967 to 0.98104, saving model to baseline_cnn_mitbih.keras\n",
      "9850/9850 - 154s - 16ms/step - acc: 0.9798 - loss: 0.0695 - val_acc: 0.9810 - val_loss: 0.0654 - learning_rate: 1.0000e-04\n",
      "Epoch 19/1000\n",
      "\n",
      "Epoch 19: val_acc improved from 0.98104 to 0.98196, saving model to baseline_cnn_mitbih.keras\n",
      "9850/9850 - 163s - 17ms/step - acc: 0.9800 - loss: 0.0676 - val_acc: 0.9820 - val_loss: 0.0659 - learning_rate: 1.0000e-04\n",
      "Epoch 20/1000\n",
      "\n",
      "Epoch 20: val_acc did not improve from 0.98196\n",
      "9850/9850 - 162s - 16ms/step - acc: 0.9810 - loss: 0.0678 - val_acc: 0.9816 - val_loss: 0.0679 - learning_rate: 1.0000e-04\n",
      "Epoch 21/1000\n",
      "\n",
      "Epoch 21: val_acc did not improve from 0.98196\n",
      "9850/9850 - 164s - 17ms/step - acc: 0.9805 - loss: 0.0671 - val_acc: 0.9800 - val_loss: 0.0691 - learning_rate: 1.0000e-04\n",
      "Epoch 22/1000\n",
      "\n",
      "Epoch 22: val_acc did not improve from 0.98196\n",
      "\n",
      "Epoch 22: ReduceLROnPlateau reducing learning rate to 1.0000000474974514e-05.\n",
      "9850/9850 - 1598s - 162ms/step - acc: 0.9813 - loss: 0.0643 - val_acc: 0.9807 - val_loss: 0.0670 - learning_rate: 1.0000e-04\n",
      "Epoch 23/1000\n",
      "\n",
      "Epoch 23: val_acc did not improve from 0.98196\n",
      "9850/9850 - 162s - 16ms/step - acc: 0.9823 - loss: 0.0618 - val_acc: 0.9817 - val_loss: 0.0671 - learning_rate: 1.0000e-05\n",
      "Epoch 24/1000\n",
      "\n",
      "Epoch 24: val_acc did not improve from 0.98196\n",
      "9850/9850 - 164s - 17ms/step - acc: 0.9821 - loss: 0.0632 - val_acc: 0.9814 - val_loss: 0.0666 - learning_rate: 1.0000e-05\n",
      "Epoch 24: early stopping\n",
      "\u001b[1m685/685\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 13ms/step\n",
      "\n",
      "\n",
      "\n",
      "Batch size:  8\n",
      "Test f1 score : 0.9008781084146766 \n",
      "Test accuracy score : 0.980038370180888 \n",
      "Total time elapsed: 5728.0853316783905\n",
      "Epoch 1/1000\n",
      "\n",
      "Epoch 1: val_acc improved from -inf to 0.81932, saving model to baseline_cnn_mitbih.keras\n",
      "78798/78798 - 1932s - 25ms/step - acc: 0.8342 - loss: 0.5268 - val_acc: 0.8193 - val_loss: 0.4780 - learning_rate: 0.0010\n",
      "Epoch 2/1000\n",
      "\n",
      "Epoch 2: val_acc improved from 0.81932 to 0.86021, saving model to baseline_cnn_mitbih.keras\n",
      "78798/78798 - 5485s - 70ms/step - acc: 0.8401 - loss: 0.4854 - val_acc: 0.8602 - val_loss: 0.4426 - learning_rate: 0.0010\n",
      "Epoch 3/1000\n",
      "\n",
      "Epoch 3: val_acc did not improve from 0.86021\n",
      "78798/78798 - 808s - 10ms/step - acc: 0.8452 - loss: 0.5087 - val_acc: 0.8321 - val_loss: 0.4584 - learning_rate: 0.0010\n",
      "Epoch 4/1000\n",
      "\n",
      "Epoch 4: val_acc improved from 0.86021 to 0.86044, saving model to baseline_cnn_mitbih.keras\n",
      "78798/78798 - 440s - 6ms/step - acc: 0.8475 - loss: 0.6018 - val_acc: 0.8604 - val_loss: 0.4637 - learning_rate: 0.0010\n",
      "Epoch 5/1000\n",
      "\n",
      "Epoch 5: val_acc did not improve from 0.86044\n",
      "78798/78798 - 438s - 6ms/step - acc: 0.8450 - loss: 3.9198 - val_acc: 0.8528 - val_loss: 0.4751 - learning_rate: 0.0010\n",
      "Epoch 6/1000\n",
      "\n",
      "Epoch 6: val_acc did not improve from 0.86044\n",
      "78798/78798 - 393s - 5ms/step - acc: 0.8414 - loss: 0.5202 - val_acc: 0.8601 - val_loss: 0.4792 - learning_rate: 0.0010\n",
      "Epoch 7/1000\n",
      "\n",
      "Epoch 7: val_acc did not improve from 0.86044\n",
      "\n",
      "Epoch 7: ReduceLROnPlateau reducing learning rate to 0.00010000000474974513.\n",
      "78798/78798 - 393s - 5ms/step - acc: 0.8372 - loss: 0.6880 - val_acc: 0.8585 - val_loss: 0.4657 - learning_rate: 0.0010\n",
      "Epoch 8/1000\n",
      "\n",
      "Epoch 8: val_acc improved from 0.86044 to 0.86421, saving model to baseline_cnn_mitbih.keras\n",
      "78798/78798 - 410s - 5ms/step - acc: 0.8567 - loss: 0.4654 - val_acc: 0.8642 - val_loss: 0.4584 - learning_rate: 1.0000e-04\n",
      "Epoch 9/1000\n",
      "\n",
      "Epoch 9: val_acc improved from 0.86421 to 0.86820, saving model to baseline_cnn_mitbih.keras\n",
      "78798/78798 - 386s - 5ms/step - acc: 0.8579 - loss: 0.4685 - val_acc: 0.8682 - val_loss: 0.4390 - learning_rate: 1.0000e-04\n",
      "Epoch 10/1000\n",
      "\n",
      "Epoch 10: val_acc improved from 0.86820 to 0.86992, saving model to baseline_cnn_mitbih.keras\n",
      "78798/78798 - 329s - 4ms/step - acc: 0.8607 - loss: 0.4706 - val_acc: 0.8699 - val_loss: 0.4374 - learning_rate: 1.0000e-04\n",
      "Epoch 11/1000\n",
      "\n",
      "Epoch 11: val_acc did not improve from 0.86992\n",
      "78798/78798 - 442s - 6ms/step - acc: 0.8607 - loss: 0.4709 - val_acc: 0.8643 - val_loss: 0.4545 - learning_rate: 1.0000e-04\n",
      "Epoch 12/1000\n",
      "\n",
      "Epoch 12: val_acc did not improve from 0.86992\n",
      "78798/78798 - 439s - 6ms/step - acc: 0.8589 - loss: 0.5407 - val_acc: 0.8681 - val_loss: 0.4364 - learning_rate: 1.0000e-04\n",
      "Epoch 13/1000\n",
      "\n",
      "Epoch 13: val_acc did not improve from 0.86992\n",
      "\n",
      "Epoch 13: ReduceLROnPlateau reducing learning rate to 1.0000000474974514e-05.\n",
      "78798/78798 - 441s - 6ms/step - acc: 0.8594 - loss: 0.4788 - val_acc: 0.8661 - val_loss: 0.4389 - learning_rate: 1.0000e-04\n",
      "Epoch 14/1000\n",
      "\n",
      "Epoch 14: val_acc did not improve from 0.86992\n",
      "78798/78798 - 435s - 6ms/step - acc: 0.8617 - loss: 0.4835 - val_acc: 0.8690 - val_loss: 0.4342 - learning_rate: 1.0000e-05\n",
      "Epoch 15/1000\n",
      "\n",
      "Epoch 15: val_acc did not improve from 0.86992\n",
      "78798/78798 - 424s - 5ms/step - acc: 0.8628 - loss: 0.4944 - val_acc: 0.8687 - val_loss: 0.4379 - learning_rate: 1.0000e-05\n",
      "Epoch 15: early stopping\n",
      "\u001b[1m685/685\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step\n",
      "\n",
      "\n",
      "\n",
      "Batch size:  1\n",
      "Test f1 score : 0.34202489019777593 \n",
      "Test accuracy score : 0.8648821487301297 \n",
      "Total time elapsed: 13198.31996011734\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "batch_sizes = [256, 32, 8, 1]\n",
    "results = []\n",
    "\n",
    "for batch_size in batch_sizes:\n",
    "\n",
    "    df_train = pd.read_csv(\"../input/mitbih_train.csv\", header=None)\n",
    "    df_train = df_train.sample(frac=1)\n",
    "    df_test = pd.read_csv(\"../input/mitbih_test.csv\", header=None)\n",
    "\n",
    "    Y = np.array(df_train[187].values).astype(np.int8)\n",
    "    X = np.array(df_train[list(range(187))].values)[..., np.newaxis]\n",
    "\n",
    "    Y_test = np.array(df_test[187].values).astype(np.int8)\n",
    "    X_test = np.array(df_test[list(range(187))].values)[..., np.newaxis]\n",
    "\n",
    "    #print(\"X train:\", np.shape(X), \"Y train\", np.shape(Y))\n",
    "    #print(\"X test:\", np.shape(X_test), \"Y test\", np.shape(Y_test))\n",
    "    t1 = time.time()\n",
    "\n",
    "    def get_model():\n",
    "        nclass = 5\n",
    "        inp = Input(shape=(187, 1))\n",
    "        img_1 = Convolution1D(16, kernel_size=5, activation=activations.relu, padding=\"valid\")(inp)\n",
    "        img_1 = Convolution1D(16, kernel_size=5, activation=activations.relu, padding=\"valid\")(img_1)\n",
    "        img_1 = MaxPool1D(pool_size=2)(img_1)\n",
    "        img_1 = Dropout(rate=0.1)(img_1)\n",
    "        img_1 = Convolution1D(32, kernel_size=3, activation=activations.relu, padding=\"valid\")(img_1)\n",
    "        img_1 = Convolution1D(32, kernel_size=3, activation=activations.relu, padding=\"valid\")(img_1)\n",
    "        img_1 = MaxPool1D(pool_size=2)(img_1)\n",
    "        img_1 = Dropout(rate=0.1)(img_1)\n",
    "        img_1 = Convolution1D(32, kernel_size=3, activation=activations.relu, padding=\"valid\")(img_1)\n",
    "        img_1 = Convolution1D(32, kernel_size=3, activation=activations.relu, padding=\"valid\")(img_1)\n",
    "        img_1 = MaxPool1D(pool_size=2)(img_1)\n",
    "        img_1 = Dropout(rate=0.1)(img_1)\n",
    "        img_1 = Convolution1D(256, kernel_size=3, activation=activations.relu, padding=\"valid\")(img_1)\n",
    "        img_1 = Convolution1D(256, kernel_size=3, activation=activations.relu, padding=\"valid\")(img_1)\n",
    "        img_1 = GlobalMaxPool1D()(img_1)\n",
    "        img_1 = Dropout(rate=0.2)(img_1)\n",
    "\n",
    "        dense_1 = Dense(64, activation=activations.relu, name=\"dense_1\")(img_1)\n",
    "        dense_1 = Dense(64, activation=activations.relu, name=\"dense_2\")(dense_1)\n",
    "        dense_1 = Dense(nclass, activation=activations.softmax, name=\"dense_3_mitbih\")(dense_1)\n",
    "\n",
    "        model = models.Model(inputs=inp, outputs=dense_1)\n",
    "        opt = optimizers.Adam(0.001)\n",
    "\n",
    "        model.compile(optimizer=opt, loss=losses.sparse_categorical_crossentropy, metrics=['acc'])\n",
    "        #model.summary()\n",
    "        return model\n",
    "\n",
    "    model = get_model()\n",
    "    file_path = \"baseline_cnn_mitbih.keras\"\n",
    "    checkpoint = ModelCheckpoint(file_path, monitor='val_acc', verbose=1, save_best_only=True, mode='max')\n",
    "    early = EarlyStopping(monitor=\"val_acc\", mode=\"max\", patience=5, verbose=1)\n",
    "    redonplat = ReduceLROnPlateau(monitor=\"val_acc\", mode=\"max\", patience=3, verbose=2)\n",
    "    callbacks_list = [checkpoint, early, redonplat]  # early\n",
    "\n",
    "    model.fit(X, Y, batch_size=batch_size, epochs=1000, verbose=2, callbacks=callbacks_list, validation_split=0.1)\n",
    "    model.load_weights(file_path)\n",
    "\n",
    "    pred_test = model.predict(X_test)\n",
    "    pred_test = np.argmax(pred_test, axis=-1)\n",
    "\n",
    "    print(\"\\n\\n\\nBatch size: \", batch_size)\n",
    "\n",
    "    f1 = f1_score(Y_test, pred_test, average=\"macro\")\n",
    "\n",
    "    print(\"Test f1 score : %s \"% f1)\n",
    "\n",
    "    acc = accuracy_score(Y_test, pred_test)\n",
    "\n",
    "    print(\"Test accuracy score : %s \"% acc)\n",
    "\n",
    "    t2 = time.time()\n",
    "    print(\"Total time elapsed:\", t2 - t1)\n",
    "    \n",
    "    results.append([batch_size, f1, acc, t2 - t1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d4450c17-8184-4d8f-b0a1-eac4bd27ce3f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[2.56000000e+02 9.17645635e-01 9.85337109e-01 1.00497526e+03]\n",
      " [3.20000000e+01 9.14916971e-01 9.85291431e-01 1.47623920e+03]\n",
      " [8.00000000e+00 9.00878108e-01 9.80038370e-01 5.72808533e+03]\n",
      " [1.00000000e+00 3.42024890e-01 8.64882149e-01 1.31983200e+04]]\n"
     ]
    }
   ],
   "source": [
    "results_ = np.array(results)\n",
    "print(results_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a1df20f1-5f27-4b34-8e23-aa48dc1d3206",
   "metadata": {},
   "outputs": [],
   "source": [
    "results_ = np.array([[2.56000000e+02, 9.17645635e-01, 9.85337109e-01, 1.00497526e+03],\n",
    " [3.20000000e+01, 9.14916971e-01, 9.85291431e-01, 1.47623920e+03],\n",
    " [8.00000000e+00, 9.00878108e-01, 9.80038370e-01, 5.72808533e+03],\n",
    " [1.00000000e+00, 3.42024890e-01, 8.64882149e-01, 1.31983200e+04]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7b353d0c-2ef9-4cc2-8c5c-133d885098d7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[2.56000000e+02 9.17645635e-01 9.85337109e-01 1.00497526e+03]\n",
      " [3.20000000e+01 9.14916971e-01 9.85291431e-01 1.47623920e+03]\n",
      " [8.00000000e+00 9.00878108e-01 9.80038370e-01 5.72808533e+03]\n",
      " [1.00000000e+00 3.42024890e-01 8.64882149e-01 1.31983200e+04]]\n"
     ]
    }
   ],
   "source": [
    "print(results_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "f578f253-1fe5-4e11-bc8a-6d8b359e260c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAjkAAAGdCAYAAADwjmIIAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjkuMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8hTgPZAAAACXBIWXMAAA9hAAAPYQGoP6dpAAAn4klEQVR4nO3df3BU9b3/8VdCzA+R3RAwu+wlYK56gQhCBRtWlJGSmyCR29R4ayQWRlK49ibKDwWSgin1VzQUFKoNpbWFGeGKdIRiqJHcoOQKMUAwBSJEbYHEMht0QnYhlBDIfv/wmzNuQQXddMmH52NmZ5pz3nv2c9hinpzsbsL8fr9fAAAAhgkP9QIAAAC6ApEDAACMROQAAAAjETkAAMBIRA4AADASkQMAAIxE5AAAACMROQAAwEgRoV5AKHV0dOjo0aPq1auXwsLCQr0cAABwEfx+v06cOCGXy6Xw8C+/XnNFR87Ro0eVkJAQ6mUAAIBvoLGxUf379//S/Vd05PTq1UvS539INpstxKsBAAAXw+fzKSEhwfo+/mWu6Mjp/BGVzWYjcgAA6Ga+7qUmvPAYAAAYicgBAABGInIAAICRiBwAAGAkIgcAABiJyAEAAEYicgAAgJGIHAAAYCQiBwAAGInIAQAARiJyAACAkYgcAABgJCIHAAAYicgBAABGigj1AgAA6ErX5W8O9RKuWIefTQ/p43MlBwAAGInIAQAARiJyAACAkYgcAABgJCIHAAAYicgBAABGInIAAICRiBwAAGAkIgcAABiJyAEAAEYicgAAgJGIHAAAYCQiBwAAGInIAQAARiJyAACAkYgcAABgJCIHAAAYicgBAABGInIAAICRiBwAAGAkIgcAABiJyAEAAEYicgAAgJGIHAAAYCQiBwAAGInIAQAARiJyAACAkS45ciorKzVp0iS5XC6FhYVp48aN1r729nbNnz9fw4YNU8+ePeVyuTRlyhQdPXo04BjNzc3Kzs6WzWZTbGyscnJydPLkyYCZvXv36o477lB0dLQSEhJUXFx83lrWr1+vwYMHKzo6WsOGDdOf/vSnSz0dAABgqEuOnNbWVg0fPlwvvfTSeftOnTqlPXv26PHHH9eePXv0+uuvq76+Xv/xH/8RMJedna26ujqVl5ertLRUlZWVmjFjhrXf5/MpNTVVAwcOVE1NjRYvXqxFixZp5cqV1syOHTt0//33KycnR++//74yMjKUkZGh/fv3X+opAQAAA4X5/X7/N75zWJg2bNigjIyML53ZtWuXvvvd7+rIkSMaMGCADhw4oKSkJO3atUujRo2SJJWVlWnixIn65JNP5HK5VFJSogULFsjj8SgyMlKSlJ+fr40bN+rgwYOSpPvuu0+tra0qLS21Hmv06NEaMWKEVqxYcVHr9/l8stvt8nq9stls3/BPAQBwObsuf3Ool3DFOvxsepcc92K/f3f5a3K8Xq/CwsIUGxsrSaqqqlJsbKwVOJKUkpKi8PBwVVdXWzNjx461AkeS0tLSVF9fr+PHj1szKSkpAY+VlpamqqqqL11LW1ubfD5fwA0AAJipSyPn9OnTmj9/vu6//36rtDwej+Lj4wPmIiIiFBcXJ4/HY804HI6Amc6vv26mc/+FFBUVyW63W7eEhIRvd4IAAOCy1WWR097erh/+8Ify+/0qKSnpqoe5JAUFBfJ6vdatsbEx1EsCAABdJKIrDtoZOEeOHNHWrVsDfl7mdDp17NixgPmzZ8+qublZTqfTmmlqagqY6fz662Y6919IVFSUoqKivvmJAQCAbiPoV3I6A+ejjz7S//7v/6pPnz4B+91ut1paWlRTU2Nt27p1qzo6OpScnGzNVFZWqr293ZopLy/XoEGD1Lt3b2umoqIi4Njl5eVyu93BPiUAANANXXLknDx5UrW1taqtrZUkHTp0SLW1tWpoaFB7e7vuvfde7d69W2vWrNG5c+fk8Xjk8Xh05swZSdKQIUM0YcIETZ8+XTt37tT27duVl5enrKwsuVwuSdLkyZMVGRmpnJwc1dXVad26dVq2bJnmzJljrWPmzJkqKyvTkiVLdPDgQS1atEi7d+9WXl5eEP5YAABAd3fJbyF/5513NG7cuPO2T506VYsWLVJiYuIF7/f222/rzjvvlPT5hwHm5eXpjTfeUHh4uDIzM7V8+XJdc8011vzevXuVm5urXbt2qW/fvnr44Yc1f/78gGOuX79eCxcu1OHDh3XjjTequLhYEydOvOhz4S3kAGA+3kIeOqF+C/m3+pyc7o7IAQDzETmhE+rI4XdXAQAAIxE5AADASEQOAAAwEpEDAACMROQAAAAjETkAAMBIRA4AADASkQMAAIxE5AAAACMROQAAwEhEDgAAMBKRAwAAjETkAAAAIxE5AADASEQOAAAwEpEDAACMROQAAAAjETkAAMBIRA4AADASkQMAAIxE5AAAACMROQAAwEhEDgAAMBKRAwAAjETkAAAAIxE5AADASEQOAAAwEpEDAACMROQAAAAjETkAAMBIRA4AADASkQMAAIxE5AAAACMROQAAwEhEDgAAMBKRAwAAjETkAAAAIxE5AADASEQOAAAwEpEDAACMROQAAAAjETkAAMBIlxw5lZWVmjRpklwul8LCwrRx48aA/X6/X4WFherXr59iYmKUkpKijz76KGCmublZ2dnZstlsio2NVU5Ojk6ePBkws3fvXt1xxx2Kjo5WQkKCiouLz1vL+vXrNXjwYEVHR2vYsGH605/+dKmnAwAADHXJkdPa2qrhw4frpZdeuuD+4uJiLV++XCtWrFB1dbV69uyptLQ0nT592prJzs5WXV2dysvLVVpaqsrKSs2YMcPa7/P5lJqaqoEDB6qmpkaLFy/WokWLtHLlSmtmx44duv/++5WTk6P3339fGRkZysjI0P79+y/1lAAAgIHC/H6//xvfOSxMGzZsUEZGhqTPr+K4XC49+uijeuyxxyRJXq9XDodDq1atUlZWlg4cOKCkpCTt2rVLo0aNkiSVlZVp4sSJ+uSTT+RyuVRSUqIFCxbI4/EoMjJSkpSfn6+NGzfq4MGDkqT77rtPra2tKi0ttdYzevRojRgxQitWrLio9ft8Ptntdnm9Xtlstm/6xwAAuIxdl7851Eu4Yh1+Nr1Ljnux37+D+pqcQ4cOyePxKCUlxdpmt9uVnJysqqoqSVJVVZViY2OtwJGklJQUhYeHq7q62poZO3asFTiSlJaWpvr6eh0/ftya+eLjdM50Pg4AALiyRQTzYB6PR5LkcDgCtjscDmufx+NRfHx84CIiIhQXFxcwk5iYeN4xOvf17t1bHo/nKx/nQtra2tTW1mZ97fP5LuX0AABAN3JFvbuqqKhIdrvduiUkJIR6SQAAoIsENXKcTqckqampKWB7U1OTtc/pdOrYsWMB+8+ePavm5uaAmQsd44uP8WUznfsvpKCgQF6v17o1NjZe6ikCAIBuIqiRk5iYKKfTqYqKCmubz+dTdXW13G63JMntdqulpUU1NTXWzNatW9XR0aHk5GRrprKyUu3t7dZMeXm5Bg0apN69e1szX3yczpnOx7mQqKgo2Wy2gBsAADDTJUfOyZMnVVtbq9raWkmfv9i4trZWDQ0NCgsL06xZs/TUU09p06ZN2rdvn6ZMmSKXy2W9A2vIkCGaMGGCpk+frp07d2r79u3Ky8tTVlaWXC6XJGny5MmKjIxUTk6O6urqtG7dOi1btkxz5syx1jFz5kyVlZVpyZIlOnjwoBYtWqTdu3crLy/v2/+pAACAbu+SX3i8e/dujRs3zvq6MzymTp2qVatWad68eWptbdWMGTPU0tKi22+/XWVlZYqOjrbus2bNGuXl5Wn8+PEKDw9XZmamli9fbu232+3asmWLcnNzNXLkSPXt21eFhYUBn6Vz2223ae3atVq4cKF++tOf6sYbb9TGjRs1dOjQb/QHAQAAzPKtPienu+NzcgDAfHxOTugY9Tk5AAAAlwsiBwAAGInIAQAARiJyAACAkYgcAABgJCIHAAAYicgBAABGInIAAICRiBwAAGAkIgcAABiJyAEAAEYicgAAgJGIHAAAYCQiBwAAGInIAQAARiJyAACAkYgcAABgJCIHAAAYicgBAABGInIAAICRiBwAAGAkIgcAABiJyAEAAEYicgAAgJGIHAAAYCQiBwAAGInIAQAARiJyAACAkYgcAABgJCIHAAAYicgBAABGInIAAICRiBwAAGAkIgcAABiJyAEAAEYicgAAgJGIHAAAYCQiBwAAGInIAQAARiJyAACAkYgcAABgJCIHAAAYicgBAABGCnrknDt3To8//rgSExMVExOj66+/Xk8++aT8fr814/f7VVhYqH79+ikmJkYpKSn66KOPAo7T3Nys7Oxs2Ww2xcbGKicnRydPngyY2bt3r+644w5FR0crISFBxcXFwT4dAADQTQU9cp577jmVlJToxRdf1IEDB/Tcc8+puLhYv/zlL62Z4uJiLV++XCtWrFB1dbV69uyptLQ0nT592prJzs5WXV2dysvLVVpaqsrKSs2YMcPa7/P5lJqaqoEDB6qmpkaLFy/WokWLtHLlymCfEgAA6IbC/F+8xBIEd999txwOh15++WVrW2ZmpmJiYvTKK6/I7/fL5XLp0Ucf1WOPPSZJ8nq9cjgcWrVqlbKysnTgwAElJSVp165dGjVqlCSprKxMEydO1CeffCKXy6WSkhItWLBAHo9HkZGRkqT8/Hxt3LhRBw8evKi1+nw+2e12eb1e2Wy2YP4xAAAuE9flbw71Eq5Yh59N75LjXuz376BfybnttttUUVGhDz/8UJL05z//We+++67uuusuSdKhQ4fk8XiUkpJi3cdutys5OVlVVVWSpKqqKsXGxlqBI0kpKSkKDw9XdXW1NTN27FgrcCQpLS1N9fX1On78+AXX1tbWJp/PF3ADAABmigj2AfPz8+Xz+TR48GD16NFD586d09NPP63s7GxJksfjkSQ5HI6A+zkcDmufx+NRfHx84EIjIhQXFxcwk5iYeN4xOvf17t37vLUVFRXp5z//eRDOEgAAXO6CfiXntdde05o1a7R27Vrt2bNHq1ev1i9+8QutXr062A91yQoKCuT1eq1bY2NjqJcEAAC6SNCv5MydO1f5+fnKysqSJA0bNkxHjhxRUVGRpk6dKqfTKUlqampSv379rPs1NTVpxIgRkiSn06ljx44FHPfs2bNqbm627u90OtXU1BQw0/l158w/ioqKUlRU1Lc/SQAAcNkL+pWcU6dOKTw88LA9evRQR0eHJCkxMVFOp1MVFRXWfp/Pp+rqarndbkmS2+1WS0uLampqrJmtW7eqo6NDycnJ1kxlZaXa29utmfLycg0aNOiCP6oCAABXlqBHzqRJk/T0009r8+bNOnz4sDZs2KClS5fqBz/4gSQpLCxMs2bN0lNPPaVNmzZp3759mjJlilwulzIyMiRJQ4YM0YQJEzR9+nTt3LlT27dvV15enrKysuRyuSRJkydPVmRkpHJyclRXV6d169Zp2bJlmjNnTrBPCQAAdENB/3HVL3/5Sz3++OP67//+bx07dkwul0v/9V//pcLCQmtm3rx5am1t1YwZM9TS0qLbb79dZWVlio6OtmbWrFmjvLw8jR8/XuHh4crMzNTy5cut/Xa7XVu2bFFubq5Gjhypvn37qrCwMOCzdAAAwJUr6J+T053wOTkAYD4+Jyd0jPucHAAAgMsBkQMAAIxE5AAAACMROQAAwEhEDgAAMBKRAwAAjETkAAAAIxE5AADASEQOAAAwEpEDAACMROQAAAAjETkAAMBIRA4AADASkQMAAIxE5AAAACMROQAAwEhEDgAAMBKRAwAAjETkAAAAIxE5AADASEQOAAAwEpEDAACMROQAAAAjETkAAMBIRA4AADASkQMAAIxE5AAAACMROQAAwEhEDgAAMBKRAwAAjETkAAAAIxE5AADASEQOAAAwEpEDAACMROQAAAAjETkAAMBIRA4AADASkQMAAIxE5AAAACMROQAAwEhEDgAAMBKRAwAAjNQlkfO3v/1NDzzwgPr06aOYmBgNGzZMu3fvtvb7/X4VFhaqX79+iomJUUpKij766KOAYzQ3Nys7O1s2m02xsbHKycnRyZMnA2b27t2rO+64Q9HR0UpISFBxcXFXnA4AAOiGgh45x48f15gxY3TVVVfpzTff1AcffKAlS5aod+/e1kxxcbGWL1+uFStWqLq6Wj179lRaWppOnz5tzWRnZ6uurk7l5eUqLS1VZWWlZsyYYe33+XxKTU3VwIEDVVNTo8WLF2vRokVauXJlsE8JAAB0Q2F+v98fzAPm5+dr+/bt+r//+78L7vf7/XK5XHr00Uf12GOPSZK8Xq8cDodWrVqlrKwsHThwQElJSdq1a5dGjRolSSorK9PEiRP1ySefyOVyqaSkRAsWLJDH41FkZKT12Bs3btTBgwcvaq0+n092u11er1c2my0IZw8AuNxcl7851Eu4Yh1+Nr1Ljnux37+DfiVn06ZNGjVqlP7zP/9T8fHx+s53vqPf/OY31v5Dhw7J4/EoJSXF2ma325WcnKyqqipJUlVVlWJjY63AkaSUlBSFh4erurramhk7dqwVOJKUlpam+vp6HT9+/IJra2trk8/nC7gBAAAzBT1y/vrXv6qkpEQ33nij3nrrLf3kJz/RI488otWrV0uSPB6PJMnhcATcz+FwWPs8Ho/i4+MD9kdERCguLi5g5kLH+OJj/KOioiLZ7XbrlpCQ8C3PFgAAXK6CHjkdHR265ZZb9Mwzz+g73/mOZsyYoenTp2vFihXBfqhLVlBQIK/Xa90aGxtDvSQAANBFgh45/fr1U1JSUsC2IUOGqKGhQZLkdDolSU1NTQEzTU1N1j6n06ljx44F7D979qyam5sDZi50jC8+xj+KioqSzWYLuAEAADMFPXLGjBmj+vr6gG0ffvihBg4cKElKTEyU0+lURUWFtd/n86m6ulput1uS5Ha71dLSopqaGmtm69at6ujoUHJysjVTWVmp9vZ2a6a8vFyDBg0KeCcXAAC4MgU9cmbPnq333ntPzzzzjD7++GOtXbtWK1euVG5uriQpLCxMs2bN0lNPPaVNmzZp3759mjJlilwulzIyMiR9fuVnwoQJmj59unbu3Knt27crLy9PWVlZcrlckqTJkycrMjJSOTk5qqur07p167Rs2TLNmTMn2KcEAAC6oYhgH/DWW2/Vhg0bVFBQoCeeeEKJiYl64YUXlJ2dbc3MmzdPra2tmjFjhlpaWnT77berrKxM0dHR1syaNWuUl5en8ePHKzw8XJmZmVq+fLm13263a8uWLcrNzdXIkSPVt29fFRYWBnyWDgAAuHIF/XNyuhM+JwcAzMfn5ISOcZ+TAwAAcDkI+o+rAKA74l/7odNV/9oHuJIDAACMROQAAAAjETkAAMBIRA4AADASkQMAAIxE5AAAACMROQAAwEhEDgAAMBKRAwAAjETkAAAAIxE5AADASEQOAAAwEpEDAACMROQAAAAjETkAAMBIRA4AADASkQMAAIxE5AAAACMROQAAwEhEDgAAMBKRAwAAjETkAAAAIxE5AADASEQOAAAwEpEDAACMROQAAAAjETkAAMBIRA4AADASkQMAAIxE5AAAACMROQAAwEhEDgAAMBKRAwAAjETkAAAAIxE5AADASEQOAAAwEpEDAACMROQAAAAjETkAAMBIRA4AADBSl0fOs88+q7CwMM2aNcvadvr0aeXm5qpPnz665pprlJmZqaampoD7NTQ0KD09XVdffbXi4+M1d+5cnT17NmDmnXfe0S233KKoqCjdcMMNWrVqVVefDgAA6Ca6NHJ27dqlX//617r55psDts+ePVtvvPGG1q9fr23btuno0aO65557rP3nzp1Tenq6zpw5ox07dmj16tVatWqVCgsLrZlDhw4pPT1d48aNU21trWbNmqUf//jHeuutt7rylAAAQDfRZZFz8uRJZWdn6ze/+Y169+5tbfd6vXr55Ze1dOlSfe9739PIkSP1+9//Xjt27NB7770nSdqyZYs++OADvfLKKxoxYoTuuusuPfnkk3rppZd05swZSdKKFSuUmJioJUuWaMiQIcrLy9O9996r559/vqtOCQAAdCNdFjm5ublKT09XSkpKwPaamhq1t7cHbB88eLAGDBigqqoqSVJVVZWGDRsmh8NhzaSlpcnn86murs6a+cdjp6WlWccAAABXtoiuOOirr76qPXv2aNeuXeft83g8ioyMVGxsbMB2h8Mhj8djzXwxcDr3d+77qhmfz6e///3viomJOe+x29ra1NbWZn3t8/ku/eQAAEC3EPQrOY2NjZo5c6bWrFmj6OjoYB/+WykqKpLdbrduCQkJoV4SAADoIkGPnJqaGh07dky33HKLIiIiFBERoW3btmn58uWKiIiQw+HQmTNn1NLSEnC/pqYmOZ1OSZLT6Tzv3VadX3/djM1mu+BVHEkqKCiQ1+u1bo2NjcE4ZQAAcBkKeuSMHz9e+/btU21trXUbNWqUsrOzrf991VVXqaKiwrpPfX29Ghoa5Ha7JUlut1v79u3TsWPHrJny8nLZbDYlJSVZM188RudM5zEuJCoqSjabLeAGAADMFPTX5PTq1UtDhw4N2NazZ0/16dPH2p6Tk6M5c+YoLi5ONptNDz/8sNxut0aPHi1JSk1NVVJSkn70ox+puLhYHo9HCxcuVG5urqKioiRJDz30kF588UXNmzdP06ZN09atW/Xaa69p8+bNwT4lAADQDXXJC4+/zvPPP6/w8HBlZmaqra1NaWlp+tWvfmXt79Gjh0pLS/WTn/xEbrdbPXv21NSpU/XEE09YM4mJidq8ebNmz56tZcuWqX///vrtb3+rtLS0UJwSAAC4zIT5/X5/qBcRKj6fT3a7XV6vlx9dAVe46/K5Chwqh59N79Lj89yGTlc9txf7/ZvfXQUAAIxE5AAAACMROQAAwEhEDgAAMBKRAwAAjETkAAAAIxE5AADASEQOAAAwEpEDAACMROQAAAAjETkAAMBIRA4AADASkQMAAIxE5AAAACMROQAAwEhEDgAAMBKRAwAAjETkAAAAIxE5AADASEQOAAAwEpEDAACMROQAAAAjETkAAMBIRA4AADASkQMAAIxE5AAAACMROQAAwEhEDgAAMBKRAwAAjETkAAAAIxE5AADASEQOAAAwEpEDAACMROQAAAAjETkAAMBIRA4AADASkQMAAIxE5AAAACMROQAAwEhEDgAAMBKRAwAAjETkAAAAIxE5AADASEGPnKKiIt16663q1auX4uPjlZGRofr6+oCZ06dPKzc3V3369NE111yjzMxMNTU1Bcw0NDQoPT1dV199teLj4zV37lydPXs2YOadd97RLbfcoqioKN1www1atWpVsE8HAAB0U0GPnG3btik3N1fvvfeeysvL1d7ertTUVLW2tlozs2fP1htvvKH169dr27ZtOnr0qO655x5r/7lz55Senq4zZ85ox44dWr16tVatWqXCwkJr5tChQ0pPT9e4ceNUW1urWbNm6cc//rHeeuutYJ8SAADohsL8fr+/Kx/g008/VXx8vLZt26axY8fK6/Xq2muv1dq1a3XvvfdKkg4ePKghQ4aoqqpKo0eP1ptvvqm7775bR48elcPhkCStWLFC8+fP16effqrIyEjNnz9fmzdv1v79+63HysrKUktLi8rKyi5qbT6fT3a7XV6vVzabLfgnD6DbuC5/c6iXcMU6/Gx6lx6f5zZ0uuq5vdjv313+mhyv1ytJiouLkyTV1NSovb1dKSkp1szgwYM1YMAAVVVVSZKqqqo0bNgwK3AkKS0tTT6fT3V1ddbMF4/ROdN5jAtpa2uTz+cLuAEAADN1aeR0dHRo1qxZGjNmjIYOHSpJ8ng8ioyMVGxsbMCsw+GQx+OxZr4YOJ37O/d91YzP59Pf//73C66nqKhIdrvduiUkJHzrcwQAAJenLo2c3Nxc7d+/X6+++mpXPsxFKygokNfrtW6NjY2hXhIAAOgiEV114Ly8PJWWlqqyslL9+/e3tjudTp05c0YtLS0BV3OamprkdDqtmZ07dwYcr/PdV1+c+cd3ZDU1NclmsykmJuaCa4qKilJUVNS3PjcAAHD5C/qVHL/fr7y8PG3YsEFbt25VYmJiwP6RI0fqqquuUkVFhbWtvr5eDQ0NcrvdkiS32619+/bp2LFj1kx5eblsNpuSkpKsmS8eo3Om8xgAAODKFvQrObm5uVq7dq3++Mc/qlevXtZraOx2u2JiYmS325WTk6M5c+YoLi5ONptNDz/8sNxut0aPHi1JSk1NVVJSkn70ox+puLhYHo9HCxcuVG5urnUl5qGHHtKLL76oefPmadq0adq6datee+01bd7Mq+gBAEAXXMkpKSmR1+vVnXfeqX79+lm3devWWTPPP/+87r77bmVmZmrs2LFyOp16/fXXrf09evRQaWmpevToIbfbrQceeEBTpkzRE088Yc0kJiZq8+bNKi8v1/Dhw7VkyRL99re/VVpaWrBPCQAAdENd/jk5lzM+JwdAJz5LJXT4nBxzGf85OQAAAKFA5AAAACMROQAAwEhEDgAAMBKRAwAAjETkAAAAIxE5AADASF32u6sAU/GZG6HT1Z+nAsAsXMkBAABGInIAAICRiBwAAGAkIgcAABiJyAEAAEYicgAAgJGIHAAAYCQiBwAAGInIAQAARiJyAACAkYgcAABgJH53VRfh9xuFDr/fCAAgcSUHAAAYisgBAABGInIAAICRiBwAAGAkIgcAABiJyAEAAEYicgAAgJGIHAAAYCQiBwAAGInIAQAARiJyAACAkYgcAABgJCIHAAAYicgBAABGInIAAICRiBwAAGAkIgcAABiJyAEAAEYicgAAgJGIHAAAYCQiBwAAGInIAQAARur2kfPSSy/puuuuU3R0tJKTk7Vz585QLwkAAFwGunXkrFu3TnPmzNHPfvYz7dmzR8OHD1daWpqOHTsW6qUBAIAQ69aRs3TpUk2fPl0PPvigkpKStGLFCl199dX63e9+F+qlAQCAEIsI9QK+qTNnzqimpkYFBQXWtvDwcKWkpKiqquqC92lra1NbW5v1tdfrlST5fL6gr6+j7VTQj4mL0xXP5xfx3IZOVz63PK+hw99Zc3XVc9t5XL/f/5Vz3TZyPvvsM507d04OhyNgu8Ph0MGDBy94n6KiIv385z8/b3tCQkKXrBGhYX8h1CtAV+G5NRPPq7m6+rk9ceKE7Hb7l+7vtpHzTRQUFGjOnDnW1x0dHWpublafPn0UFhYWwpVdXnw+nxISEtTY2CibzRbq5SBIeF7NxXNrLp7bC/P7/Tpx4oRcLtdXznXbyOnbt6969OihpqamgO1NTU1yOp0XvE9UVJSioqICtsXGxnbVErs9m83GXyoD8byai+fWXDy35/uqKziduu0LjyMjIzVy5EhVVFRY2zo6OlRRUSG32x3ClQEAgMtBt72SI0lz5szR1KlTNWrUKH33u9/VCy+8oNbWVj344IOhXhoAAAixbh059913nz799FMVFhbK4/FoxIgRKisrO+/FyLg0UVFR+tnPfnbej/bQvfG8movn1lw8t99OmP/r3n8FAADQDXXb1+QAAAB8FSIHAAAYicgBAABGInIAAICRiJwrQFFRkW699Vb16tVL8fHxysjIUH19fcDMnXfeqbCwsIDbQw89dN6xVq1apZtvvlnR0dGKj49Xbm7uP+s0cJFKSkp08803Wx8e5na79eabb0qSmpub9fDDD2vQoEGKiYnRgAED9Mgjj1i/xw3dx7lz5/T4448rMTFRMTExuv766/Xkk09+7e/yQfdQWVmpSZMmyeVyKSwsTBs3bgz1krqlbv0Wclycbdu2KTc3V7feeqvOnj2rn/70p0pNTdUHH3ygnj17WnPTp0/XE088YX199dVXBxxn6dKlWrJkiRYvXqzk5GS1trbq8OHD/6zTwEXq37+/nn32Wd14443y+/1avXq1vv/97+v999+X3+/X0aNH9Ytf/EJJSUk6cuSIHnroIR09elR/+MMfQr10XILnnntOJSUlWr16tW666Sbt3r1bDz74oOx2ux555JFQLw/fUmtrq4YPH65p06bpnnvuCfVyui3eQn4F+vTTTxUfH69t27Zp7Nixkj6/kjNixAi98MILF7zP8ePH9S//8i964403NH78+H/iahEMcXFxWrx4sXJycs7bt379ej3wwANqbW1VRAT/7uku7r77bjkcDr388svWtszMTMXExOiVV14J4coQbGFhYdqwYYMyMjJCvZRuhx9XXYE6fzQRFxcXsH3NmjXq27evhg4dqoKCAp06dcraV15ero6ODv3tb3/TkCFD1L9/f/3whz9UY2PjP3XtuDTnzp3Tq6++qtbW1i/9dSder1c2m43A6WZuu+02VVRU6MMPP5Qk/fnPf9a7776ru+66K8QrAy4f/FftCtPR0aFZs2ZpzJgxGjp0qLV98uTJGjhwoFwul/bu3av58+ervr5er7/+uiTpr3/9qzo6OvTMM89o2bJlstvtWrhwof793/9de/fuVWRkZKhOCRewb98+ud1unT59Wtdcc402bNigpKSk8+Y+++wzPfnkk5oxY0YIVolvIz8/Xz6fT4MHD1aPHj107tw5Pf3008rOzg710oDLBpFzhcnNzdX+/fv17rvvBmz/4je5YcOGqV+/fho/frz+8pe/6Prrr1dHR4fa29u1fPlypaamSpL+53/+R06nU2+//bbS0tL+qeeBrzZo0CDV1tbK6/XqD3/4g6ZOnapt27YFhI7P51N6erqSkpK0aNGi0C0W38hrr72mNWvWaO3atbrppptUW1urWbNmyeVyaerUqaFeHnBZIHKuIHl5eSotLVVlZaX69+//lbPJycmSpI8//ljXX3+9+vXrJ0kB3ySvvfZa9e3bVw0NDV23aHwjkZGRuuGGGyRJI0eO1K5du7Rs2TL9+te/liSdOHFCEyZMUK9evbRhwwZdddVVoVwuvoG5c+cqPz9fWVlZkj7/x8mRI0dUVFRE5AD/H6/JuQL4/X7l5eVpw4YN2rp1qxITE7/2PrW1tZJkxc2YMWMkKeCt583Nzfrss880cODA4C8aQdXR0aG2tjZJn1/BSU1NVWRkpDZt2qTo6OgQrw7fxKlTpxQeHvif8B49eqijoyNEKwIuP1zJuQLk5uZq7dq1+uMf/6hevXrJ4/FIkux2u2JiYvSXv/xFa9eu1cSJE9WnTx/t3btXs2fP1tixY3XzzTdLkv7t3/5N3//+9zVz5kytXLlSNptNBQUFGjx4sMaNGxfK08M/KCgo0F133aUBAwboxIkTWrt2rd555x299dZbVuCcOnVKr7zyinw+n3w+n6TPr8z16NEjxKvHxZo0aZKefvppDRgwQDfddJPef/99LV26VNOmTQv10hAEJ0+e1Mcff2x9fejQIdXW1iouLk4DBgwI4cq6GT+MJ+mCt9///vd+v9/vb2ho8I8dO9YfFxfnj4qK8t9www3+uXPn+r1eb8BxvF6vf9q0af7Y2Fh/XFyc/wc/+IG/oaEhBGeErzJt2jT/wIED/ZGRkf5rr73WP378eP+WLVv8fr/f//bbb3/p/x8OHToU2oXjkvh8Pv/MmTP9AwYM8EdHR/v/9V//1b9gwQJ/W1tbqJeGIPiyv6tTp04N9dK6FT4nBwAAGInX5AAAACMROQAAwEhEDgAAMBKRAwAAjETkAAAAIxE5AADASEQOAAAwEpEDAACMROQAAAAjETkAAMBIRA4AADASkQMAAIz0/wDkX1geic7AyQAAAABJRU5ErkJggg==",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.bar(['256', '32', '8', '1'], results_.T[3])\n",
    "plt.show()\n",
    "plt.plot(['256', '32', '8', '1'], results_.T[2])\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
